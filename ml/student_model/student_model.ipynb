{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "import tensorflow as tf\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA</th>\n",
       "      <th>Certifications &amp; Skills</th>\n",
       "      <th>College</th>\n",
       "      <th>City</th>\n",
       "      <th>College Tier</th>\n",
       "      <th>City Tier</th>\n",
       "      <th>Placement Ratio</th>\n",
       "      <th>CIBIL Score</th>\n",
       "      <th>Parent Income (LPA)</th>\n",
       "      <th>Salary (INR)</th>\n",
       "      <th>Credit Worthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.25</td>\n",
       "      <td>6</td>\n",
       "      <td>College_100</td>\n",
       "      <td>City_10</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>0.832075</td>\n",
       "      <td>777</td>\n",
       "      <td>10.997215</td>\n",
       "      <td>1.980164e+06</td>\n",
       "      <td>0.597033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.70</td>\n",
       "      <td>3</td>\n",
       "      <td>College_73</td>\n",
       "      <td>City_3</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>0.544938</td>\n",
       "      <td>358</td>\n",
       "      <td>10.139370</td>\n",
       "      <td>1.973939e+06</td>\n",
       "      <td>0.508709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.39</td>\n",
       "      <td>1</td>\n",
       "      <td>College_16</td>\n",
       "      <td>City_8</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>0.528553</td>\n",
       "      <td>409</td>\n",
       "      <td>12.808232</td>\n",
       "      <td>1.988770e+06</td>\n",
       "      <td>0.428536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.59</td>\n",
       "      <td>4</td>\n",
       "      <td>College_46</td>\n",
       "      <td>City_5</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>0.847024</td>\n",
       "      <td>778</td>\n",
       "      <td>12.583080</td>\n",
       "      <td>2.043800e+06</td>\n",
       "      <td>0.634251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.94</td>\n",
       "      <td>2</td>\n",
       "      <td>College_59</td>\n",
       "      <td>City_6</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>0.834346</td>\n",
       "      <td>893</td>\n",
       "      <td>2.849388</td>\n",
       "      <td>7.258565e+05</td>\n",
       "      <td>0.455229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GPA  Certifications & Skills      College     City College Tier City Tier  \\\n",
       "0  6.25                        6  College_100  City_10       Tier 2    Tier 2   \n",
       "1  9.70                        3   College_73   City_3       Tier 3    Tier 2   \n",
       "2  8.39                        1   College_16   City_8       Tier 3    Tier 2   \n",
       "3  7.59                        4   College_46   City_5       Tier 2    Tier 2   \n",
       "4  4.94                        2   College_59   City_6       Tier 2    Tier 2   \n",
       "\n",
       "   Placement Ratio  CIBIL Score  Parent Income (LPA)  Salary (INR)  \\\n",
       "0         0.832075          777            10.997215  1.980164e+06   \n",
       "1         0.544938          358            10.139370  1.973939e+06   \n",
       "2         0.528553          409            12.808232  1.988770e+06   \n",
       "3         0.847024          778            12.583080  2.043800e+06   \n",
       "4         0.834346          893             2.849388  7.258565e+05   \n",
       "\n",
       "   Credit Worthiness  \n",
       "0           0.597033  \n",
       "1           0.508709  \n",
       "2           0.428536  \n",
       "3           0.634251  \n",
       "4           0.455229  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/student_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA</th>\n",
       "      <th>Certifications &amp; Skills</th>\n",
       "      <th>City</th>\n",
       "      <th>College Tier</th>\n",
       "      <th>City Tier</th>\n",
       "      <th>Placement Ratio</th>\n",
       "      <th>CIBIL Score</th>\n",
       "      <th>Parent Income (LPA)</th>\n",
       "      <th>Salary (INR)</th>\n",
       "      <th>Credit Worthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.25</td>\n",
       "      <td>6</td>\n",
       "      <td>City_10</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>0.832075</td>\n",
       "      <td>777</td>\n",
       "      <td>10.997215</td>\n",
       "      <td>1.980164e+06</td>\n",
       "      <td>0.597033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.70</td>\n",
       "      <td>3</td>\n",
       "      <td>City_3</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>0.544938</td>\n",
       "      <td>358</td>\n",
       "      <td>10.139370</td>\n",
       "      <td>1.973939e+06</td>\n",
       "      <td>0.508709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.39</td>\n",
       "      <td>1</td>\n",
       "      <td>City_8</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>0.528553</td>\n",
       "      <td>409</td>\n",
       "      <td>12.808232</td>\n",
       "      <td>1.988770e+06</td>\n",
       "      <td>0.428536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.59</td>\n",
       "      <td>4</td>\n",
       "      <td>City_5</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>0.847024</td>\n",
       "      <td>778</td>\n",
       "      <td>12.583080</td>\n",
       "      <td>2.043800e+06</td>\n",
       "      <td>0.634251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.94</td>\n",
       "      <td>2</td>\n",
       "      <td>City_6</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>0.834346</td>\n",
       "      <td>893</td>\n",
       "      <td>2.849388</td>\n",
       "      <td>7.258565e+05</td>\n",
       "      <td>0.455229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GPA  Certifications & Skills     City College Tier City Tier  \\\n",
       "0  6.25                        6  City_10       Tier 2    Tier 2   \n",
       "1  9.70                        3   City_3       Tier 3    Tier 2   \n",
       "2  8.39                        1   City_8       Tier 3    Tier 2   \n",
       "3  7.59                        4   City_5       Tier 2    Tier 2   \n",
       "4  4.94                        2   City_6       Tier 2    Tier 2   \n",
       "\n",
       "   Placement Ratio  CIBIL Score  Parent Income (LPA)  Salary (INR)  \\\n",
       "0         0.832075          777            10.997215  1.980164e+06   \n",
       "1         0.544938          358            10.139370  1.973939e+06   \n",
       "2         0.528553          409            12.808232  1.988770e+06   \n",
       "3         0.847024          778            12.583080  2.043800e+06   \n",
       "4         0.834346          893             2.849388  7.258565e+05   \n",
       "\n",
       "   Credit Worthiness  \n",
       "0           0.597033  \n",
       "1           0.508709  \n",
       "2           0.428536  \n",
       "3           0.634251  \n",
       "4           0.455229  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('College', axis='columns', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA</th>\n",
       "      <th>Certifications &amp; Skills</th>\n",
       "      <th>College Tier</th>\n",
       "      <th>City Tier</th>\n",
       "      <th>Placement Ratio</th>\n",
       "      <th>CIBIL Score</th>\n",
       "      <th>Parent Income (LPA)</th>\n",
       "      <th>Salary (INR)</th>\n",
       "      <th>Credit Worthiness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.25</td>\n",
       "      <td>6</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>0.832075</td>\n",
       "      <td>777</td>\n",
       "      <td>10.997215</td>\n",
       "      <td>1.980164e+06</td>\n",
       "      <td>0.597033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.70</td>\n",
       "      <td>3</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>0.544938</td>\n",
       "      <td>358</td>\n",
       "      <td>10.139370</td>\n",
       "      <td>1.973939e+06</td>\n",
       "      <td>0.508709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.39</td>\n",
       "      <td>1</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>0.528553</td>\n",
       "      <td>409</td>\n",
       "      <td>12.808232</td>\n",
       "      <td>1.988770e+06</td>\n",
       "      <td>0.428536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.59</td>\n",
       "      <td>4</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>0.847024</td>\n",
       "      <td>778</td>\n",
       "      <td>12.583080</td>\n",
       "      <td>2.043800e+06</td>\n",
       "      <td>0.634251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.94</td>\n",
       "      <td>2</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>0.834346</td>\n",
       "      <td>893</td>\n",
       "      <td>2.849388</td>\n",
       "      <td>7.258565e+05</td>\n",
       "      <td>0.455229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GPA  Certifications & Skills College Tier City Tier  Placement Ratio  \\\n",
       "0  6.25                        6       Tier 2    Tier 2         0.832075   \n",
       "1  9.70                        3       Tier 3    Tier 2         0.544938   \n",
       "2  8.39                        1       Tier 3    Tier 2         0.528553   \n",
       "3  7.59                        4       Tier 2    Tier 2         0.847024   \n",
       "4  4.94                        2       Tier 2    Tier 2         0.834346   \n",
       "\n",
       "   CIBIL Score  Parent Income (LPA)  Salary (INR)  Credit Worthiness  \n",
       "0          777            10.997215  1.980164e+06           0.597033  \n",
       "1          358            10.139370  1.973939e+06           0.508709  \n",
       "2          409            12.808232  1.988770e+06           0.428536  \n",
       "3          778            12.583080  2.043800e+06           0.634251  \n",
       "4          893             2.849388  7.258565e+05           0.455229  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('City', axis='columns', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['College Tier', 'City Tier'], drop_first=True, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA</th>\n",
       "      <th>Certifications &amp; Skills</th>\n",
       "      <th>Placement Ratio</th>\n",
       "      <th>CIBIL Score</th>\n",
       "      <th>Parent Income (LPA)</th>\n",
       "      <th>Salary (INR)</th>\n",
       "      <th>Credit Worthiness</th>\n",
       "      <th>College Tier_Tier 2</th>\n",
       "      <th>College Tier_Tier 3</th>\n",
       "      <th>City Tier_Tier 2</th>\n",
       "      <th>City Tier_Tier 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.25</td>\n",
       "      <td>6</td>\n",
       "      <td>0.832075</td>\n",
       "      <td>777</td>\n",
       "      <td>10.997215</td>\n",
       "      <td>1.980164e+06</td>\n",
       "      <td>0.597033</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.70</td>\n",
       "      <td>3</td>\n",
       "      <td>0.544938</td>\n",
       "      <td>358</td>\n",
       "      <td>10.139370</td>\n",
       "      <td>1.973939e+06</td>\n",
       "      <td>0.508709</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528553</td>\n",
       "      <td>409</td>\n",
       "      <td>12.808232</td>\n",
       "      <td>1.988770e+06</td>\n",
       "      <td>0.428536</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.59</td>\n",
       "      <td>4</td>\n",
       "      <td>0.847024</td>\n",
       "      <td>778</td>\n",
       "      <td>12.583080</td>\n",
       "      <td>2.043800e+06</td>\n",
       "      <td>0.634251</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.94</td>\n",
       "      <td>2</td>\n",
       "      <td>0.834346</td>\n",
       "      <td>893</td>\n",
       "      <td>2.849388</td>\n",
       "      <td>7.258565e+05</td>\n",
       "      <td>0.455229</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GPA  Certifications & Skills  Placement Ratio  CIBIL Score  \\\n",
       "0  6.25                        6         0.832075          777   \n",
       "1  9.70                        3         0.544938          358   \n",
       "2  8.39                        1         0.528553          409   \n",
       "3  7.59                        4         0.847024          778   \n",
       "4  4.94                        2         0.834346          893   \n",
       "\n",
       "   Parent Income (LPA)  Salary (INR)  Credit Worthiness  College Tier_Tier 2  \\\n",
       "0            10.997215  1.980164e+06           0.597033                    1   \n",
       "1            10.139370  1.973939e+06           0.508709                    0   \n",
       "2            12.808232  1.988770e+06           0.428536                    0   \n",
       "3            12.583080  2.043800e+06           0.634251                    1   \n",
       "4             2.849388  7.258565e+05           0.455229                    1   \n",
       "\n",
       "   College Tier_Tier 3  City Tier_Tier 2  City Tier_Tier 3  \n",
       "0                    0                 1                 0  \n",
       "1                    1                 1                 0  \n",
       "2                    1                 1                 0  \n",
       "3                    0                 1                 0  \n",
       "4                    0                 1                 0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = scaler.fit_transform(data) \n",
    "# Convert the scaled data back to a DataFrame with original column names\n",
    "data = pd.DataFrame(scaled_data, columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA</th>\n",
       "      <th>Certifications &amp; Skills</th>\n",
       "      <th>Placement Ratio</th>\n",
       "      <th>CIBIL Score</th>\n",
       "      <th>Parent Income (LPA)</th>\n",
       "      <th>Salary (INR)</th>\n",
       "      <th>Credit Worthiness</th>\n",
       "      <th>College Tier_Tier 2</th>\n",
       "      <th>College Tier_Tier 3</th>\n",
       "      <th>City Tier_Tier 2</th>\n",
       "      <th>City Tier_Tier 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.664371</td>\n",
       "      <td>0.796327</td>\n",
       "      <td>0.391183</td>\n",
       "      <td>0.484872</td>\n",
       "      <td>0.610110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.089730</td>\n",
       "      <td>0.096828</td>\n",
       "      <td>0.353886</td>\n",
       "      <td>0.483435</td>\n",
       "      <td>0.490176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.731667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.056939</td>\n",
       "      <td>0.181970</td>\n",
       "      <td>0.469923</td>\n",
       "      <td>0.486858</td>\n",
       "      <td>0.381310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.598333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.694288</td>\n",
       "      <td>0.797997</td>\n",
       "      <td>0.460134</td>\n",
       "      <td>0.499561</td>\n",
       "      <td>0.660649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.668917</td>\n",
       "      <td>0.989983</td>\n",
       "      <td>0.036930</td>\n",
       "      <td>0.195333</td>\n",
       "      <td>0.417556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GPA  Certifications & Skills  Placement Ratio  CIBIL Score  \\\n",
       "0  0.375000                 0.666667         0.664371     0.796327   \n",
       "1  0.950000                 0.333333         0.089730     0.096828   \n",
       "2  0.731667                 0.111111         0.056939     0.181970   \n",
       "3  0.598333                 0.444444         0.694288     0.797997   \n",
       "4  0.156667                 0.222222         0.668917     0.989983   \n",
       "\n",
       "   Parent Income (LPA)  Salary (INR)  Credit Worthiness  College Tier_Tier 2  \\\n",
       "0             0.391183      0.484872           0.610110                  1.0   \n",
       "1             0.353886      0.483435           0.490176                  0.0   \n",
       "2             0.469923      0.486858           0.381310                  0.0   \n",
       "3             0.460134      0.499561           0.660649                  1.0   \n",
       "4             0.036930      0.195333           0.417556                  1.0   \n",
       "\n",
       "   College Tier_Tier 3  City Tier_Tier 2  City Tier_Tier 3  \n",
       "0                  0.0               1.0               0.0  \n",
       "1                  1.0               1.0               0.0  \n",
       "2                  1.0               1.0               0.0  \n",
       "3                  0.0               1.0               0.0  \n",
       "4                  0.0               1.0               0.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddhanthmoraje/Developer/ml/dataset_hackathon/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0420 - mae: 0.2219 - val_loss: 0.0248 - val_mae: 0.1934\n",
      "Epoch 2/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - mae: 0.1090 - val_loss: 0.0153 - val_mae: 0.1490\n",
      "Epoch 3/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mae: 0.0871 - val_loss: 0.0090 - val_mae: 0.1111\n",
      "Epoch 4/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0045 - mae: 0.0743 - val_loss: 0.0064 - val_mae: 0.0902\n",
      "Epoch 5/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - mae: 0.0659 - val_loss: 0.0040 - val_mae: 0.0686\n",
      "Epoch 6/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0033 - mae: 0.0614 - val_loss: 0.0046 - val_mae: 0.0712\n",
      "Epoch 7/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 - mae: 0.0565 - val_loss: 0.0030 - val_mae: 0.0566\n",
      "Epoch 8/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0024 - mae: 0.0519 - val_loss: 0.0035 - val_mae: 0.0598\n",
      "Epoch 9/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0484 - val_loss: 0.0027 - val_mae: 0.0506\n",
      "Epoch 10/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0454 - val_loss: 0.0022 - val_mae: 0.0460\n",
      "Epoch 11/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0016 - mae: 0.0428 - val_loss: 0.0022 - val_mae: 0.0441\n",
      "Epoch 12/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0396 - val_loss: 0.0020 - val_mae: 0.0426\n",
      "Epoch 13/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0385 - val_loss: 0.0018 - val_mae: 0.0421\n",
      "Epoch 14/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mae: 0.0374 - val_loss: 0.0022 - val_mae: 0.0457\n",
      "Epoch 15/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0358 - val_loss: 0.0023 - val_mae: 0.0481\n",
      "Epoch 16/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0352 - val_loss: 0.0022 - val_mae: 0.0439\n",
      "Epoch 17/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0010 - mae: 0.0332 - val_loss: 0.0021 - val_mae: 0.0444\n",
      "Epoch 18/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0010 - mae: 0.0332 - val_loss: 0.0019 - val_mae: 0.0416\n",
      "Epoch 19/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.7619e-04 - mae: 0.0318 - val_loss: 0.0021 - val_mae: 0.0425\n",
      "Epoch 20/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.2478e-04 - mae: 0.0312 - val_loss: 0.0018 - val_mae: 0.0400\n",
      "Epoch 21/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7739e-04 - mae: 0.0301 - val_loss: 0.0025 - val_mae: 0.0482\n",
      "Epoch 22/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9069e-04 - mae: 0.0300 - val_loss: 0.0019 - val_mae: 0.0409\n",
      "Epoch 23/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0785e-04 - mae: 0.0295 - val_loss: 0.0024 - val_mae: 0.0469\n",
      "Epoch 24/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.8752e-04 - mae: 0.0288 - val_loss: 0.0019 - val_mae: 0.0402\n",
      "Epoch 25/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.5919e-04 - mae: 0.0278 - val_loss: 0.0021 - val_mae: 0.0439\n",
      "Epoch 26/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0386e-04 - mae: 0.0273 - val_loss: 0.0021 - val_mae: 0.0441\n",
      "Epoch 27/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1667e-04 - mae: 0.0273 - val_loss: 0.0015 - val_mae: 0.0364\n",
      "Epoch 28/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8018e-04 - mae: 0.0267 - val_loss: 0.0017 - val_mae: 0.0384\n",
      "Epoch 29/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.0108e-04 - mae: 0.0267 - val_loss: 0.0021 - val_mae: 0.0450\n",
      "Epoch 30/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3815e-04 - mae: 0.0255 - val_loss: 0.0017 - val_mae: 0.0397\n",
      "Epoch 31/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.6485e-04 - mae: 0.0264 - val_loss: 0.0016 - val_mae: 0.0379\n",
      "Epoch 32/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1234e-04 - mae: 0.0256 - val_loss: 0.0021 - val_mae: 0.0414\n",
      "Epoch 33/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8868e-04 - mae: 0.0250 - val_loss: 0.0016 - val_mae: 0.0372\n",
      "Epoch 34/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0112e-04 - mae: 0.0246 - val_loss: 0.0014 - val_mae: 0.0337\n",
      "Epoch 35/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.8702e-04 - mae: 0.0246 - val_loss: 0.0018 - val_mae: 0.0401\n",
      "Epoch 36/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.6691e-04 - mae: 0.0242 - val_loss: 0.0014 - val_mae: 0.0344\n",
      "Epoch 37/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1956e-04 - mae: 0.0237 - val_loss: 0.0017 - val_mae: 0.0382\n",
      "Epoch 38/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.2041e-04 - mae: 0.0231 - val_loss: 0.0017 - val_mae: 0.0406\n",
      "Epoch 39/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3228e-04 - mae: 0.0234 - val_loss: 0.0018 - val_mae: 0.0377\n",
      "Epoch 40/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.2362e-04 - mae: 0.0234 - val_loss: 0.0016 - val_mae: 0.0375\n",
      "Epoch 41/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.8935e-04 - mae: 0.0226 - val_loss: 0.0016 - val_mae: 0.0370\n",
      "Epoch 42/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3651e-04 - mae: 0.0231 - val_loss: 0.0014 - val_mae: 0.0353\n",
      "Epoch 43/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.8819e-04 - mae: 0.0226 - val_loss: 0.0017 - val_mae: 0.0391\n",
      "Epoch 44/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.7281e-04 - mae: 0.0223 - val_loss: 0.0016 - val_mae: 0.0331\n",
      "Epoch 45/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8183e-04 - mae: 0.0224 - val_loss: 0.0013 - val_mae: 0.0334\n",
      "Epoch 46/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2425e-04 - mae: 0.0214 - val_loss: 0.0017 - val_mae: 0.0400\n",
      "Epoch 47/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.7156e-04 - mae: 0.0221 - val_loss: 0.0012 - val_mae: 0.0332\n",
      "Epoch 48/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.6964e-04 - mae: 0.0219 - val_loss: 0.0014 - val_mae: 0.0338\n",
      "Epoch 49/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.9604e-04 - mae: 0.0222 - val_loss: 0.0015 - val_mae: 0.0375\n",
      "Epoch 50/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6158e-04 - mae: 0.0218 - val_loss: 0.0013 - val_mae: 0.0356\n",
      "Epoch 51/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.6490e-04 - mae: 0.0222 - val_loss: 0.0012 - val_mae: 0.0323\n",
      "Epoch 52/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.5181e-04 - mae: 0.0218 - val_loss: 0.0017 - val_mae: 0.0368\n",
      "Epoch 53/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4896e-04 - mae: 0.0215 - val_loss: 0.0010 - val_mae: 0.0307\n",
      "Epoch 54/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2983e-04 - mae: 0.0211 - val_loss: 0.0012 - val_mae: 0.0314\n",
      "Epoch 55/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2352e-04 - mae: 0.0211 - val_loss: 0.0012 - val_mae: 0.0326\n",
      "Epoch 56/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3039e-04 - mae: 0.0205 - val_loss: 0.0011 - val_mae: 0.0312\n",
      "Epoch 57/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2723e-04 - mae: 0.0208 - val_loss: 0.0017 - val_mae: 0.0392\n",
      "Epoch 58/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2122e-04 - mae: 0.0209 - val_loss: 0.0016 - val_mae: 0.0363\n",
      "Epoch 59/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1241e-04 - mae: 0.0203 - val_loss: 0.0014 - val_mae: 0.0359\n",
      "Epoch 60/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.1227e-04 - mae: 0.0209 - val_loss: 0.0012 - val_mae: 0.0328\n",
      "Epoch 61/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7737e-04 - mae: 0.0200 - val_loss: 0.0013 - val_mae: 0.0340\n",
      "Epoch 62/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0135e-04 - mae: 0.0203 - val_loss: 0.0016 - val_mae: 0.0390\n",
      "Epoch 63/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8769e-04 - mae: 0.0202 - val_loss: 0.0017 - val_mae: 0.0382\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 0.0010 - mae: 0.0308  \n",
      "Test Loss: 0.0010320581495761871, Test MAE: 0.030748000368475914\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step\n",
      "Predicted: [0.48498482], Actual: 0.47856828570365906\n",
      "Predicted: [0.6296092], Actual: 0.6701505780220032\n",
      "Predicted: [0.51103514], Actual: 0.5050362348556519\n",
      "Predicted: [0.3878996], Actual: 0.3759775757789612\n",
      "Predicted: [0.52726275], Actual: 0.5503456592559814\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Preprocess your data\n",
    "# Assuming the 8 features are columns: 'academic_performance', 'certification_skills', etc.\n",
    "X = data[['GPA', 'Certifications & Skills', 'Placement Ratio', \n",
    "           'CIBIL Score', 'Parent Income (LPA)', 'Salary (INR)', 'College Tier_Tier 2','College Tier_Tier 3','City Tier_Tier 2','City Tier_Tier 3']].values\n",
    "y = data['Credit Worthiness'].values\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 4: Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "# Step 5: Define the custom loss function\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # Modify the impact of skills and certifications when academic performance is low\n",
    "    skills_weight = X_train[:, 1]  # Assuming certifications & skills is the second feature\n",
    "    academic_weight = X_train[:, 0]  # Assuming academic performance is the first feature\n",
    "    \n",
    "    # Less penalty when certifications are high but academic performance is low\n",
    "    penalty_factor = 1 / (1 + tf.exp(skills_weight - academic_weight))\n",
    "    \n",
    "    # Standard MSE loss scaled by penalty factor\n",
    "    loss = tf.reduce_mean(tf.square(y_true - y_pred) * penalty_factor)\n",
    "    return loss\n",
    "\n",
    "# Step 6: Optional Attention Layer for dynamic feature weighting\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.attention_weights = self.add_weight(name='attention_weights', shape=(input_shape[-1], 1),initializer='random_normal', trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attention_scores = tf.nn.softmax(tf.matmul(inputs, self.attention_weights), axis=1)\n",
    "        output = inputs * attention_scores\n",
    "        return output\n",
    "\n",
    "# Step 7: Build the Dense Neural Network model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer and first hidden layer\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout for regularization\n",
    "\n",
    "# Attention layer (optional)\n",
    "model.add(AttentionLayer())  # Adds attention over the features\n",
    "\n",
    "# Second hidden layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Third hidden layer\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "# Output layer (1 neuron for creditworthiness score)\n",
    "model.add(Dense(1, activation='linear'))  # Use 'sigmoid' for bounded score between 0 and 1\n",
    "\n",
    "# Step 8: Compile the model with custom loss function\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=custom_loss, metrics=['mae'])\n",
    "\n",
    "# Step 9: TensorBoard setup\n",
    "# Define the logs directory to save the TensorBoard logs\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Step 10: Add early stopping and train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, \n",
    "                    batch_size=32, callbacks=[early_stopping, tensorboard_callback])\n",
    "\n",
    "# Step 11: Evaluate the model on test data\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test MAE: {mae}\")\n",
    "\n",
    "# Step 12: Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Optional: Analyze the predictions\n",
    "for i in range(5):  # Display first 5 predictions\n",
    "    print(f\"Predicted: {predictions[i]}, Actual: {y_test[i]}\")\n",
    "\n",
    "# Step 13: Launch TensorBoard from the command line\n",
    "# Use this command in your terminal to start TensorBoard and visualize the logs\n",
    "# tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.9217\n",
      "Accuracy within 10% tolerance: 83.70%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculate R² score\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# Calculate Custom Accuracy within 10% tolerance\n",
    "tolerance = 0.10\n",
    "# Check if predictions are within 10% of actual values\n",
    "within_tolerance = np.abs((predictions.flatten() - y_test) / y_test) <= tolerance\n",
    "# Calculate the percentage of accurate predictions\n",
    "accuracy_within_tolerance = np.mean(within_tolerance) * 100\n",
    "print(f\"Accuracy within 10% tolerance: {accuracy_within_tolerance:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.03\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.00\n",
      "Root Mean Squared Error (RMSE): 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddhanthmoraje/Developer/ml/dataset_hackathon/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)  # RMSE is the square root of MSE\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open(\"student_model.pkl\",\"wb\")\n",
    "pickle.dump(model,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
